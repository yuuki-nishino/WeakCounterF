{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f58137e-b018-49d5-9e3b-308b6dea3289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy import abs, max \n",
    "import scipy\n",
    "from scipy import interpolate\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import glob\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input,LSTM,Dense,Dropout,Activation,noise,normalization,TimeDistributed,Flatten,Masking,Embedding,Conv1D, MaxPooling1D, RepeatVector, Permute, Lambda, Multiply,Reshape\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.callbacks import EarlyStopping\n",
    "from IPython.display import SVG\n",
    "import keras_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras import backend as K\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005121e1-a14c-4704-8ff2-cc0aa67f9e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = ['A','B','C','D','E','F','G','H','I']\n",
    "subject_list1 = subject_list[:3]\n",
    "subject_list2 = subject_list[3:]\n",
    "action_list = ['pushup','squat','abs']\n",
    "action_dict = {'pushup':'p','squat':'s','abs':'a'}\n",
    "target = 'A'\n",
    "if target in subject_list1:\n",
    "    subject_list1.remove(target)\n",
    "if target in subject_list2:\n",
    "    subject_list2.remove(target)\n",
    "print(subject_list1)\n",
    "print(subject_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66dacbf-c70c-4cfa-b0b2-c0b2eb30d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_num = 15\n",
    "aug_num = 100\n",
    "aug_num_l = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d4a222-3890-48ef-8467-b24a36bb9d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_base_dataset(subject,use_id,aug_num):\n",
    "    dataset = np.zeros((0,3,35000))\n",
    "    cnt_pushup = np.zeros(0)\n",
    "    cnt_squat = np.zeros(0)\n",
    "    cnt_abs = np.zeros(0)\n",
    "    \n",
    "    for i in use_id:\n",
    "        npz = np.load('../data/raw_data/'+subject+'/'+str(i)+'.npz')\n",
    "        acc = npz['d']\n",
    "        c_p = npz['p']\n",
    "        c_s = npz['s']\n",
    "        c_a = npz['a']\n",
    "        \n",
    "        #zero padding\n",
    "        data = np.zeros((1,3,35000))\n",
    "        data[0,:,:acc.shape[1]] = acc\n",
    "        \n",
    "        #append\n",
    "        dataset = np.append(dataset,data,axis=0)\n",
    "        cnt_pushup = np.append(cnt_pushup,c_p)\n",
    "        cnt_squat = np.append(cnt_squat,c_s)\n",
    "        cnt_abs = np.append(cnt_abs,c_a)\n",
    "        \n",
    "        #Data Augmentation\n",
    "        npz_aug = np.load('../data/augmented_data/'+subject+'/'+str(i)+'/'+str(aug_num)+'.npz')\n",
    "        data_aug = npz_aug['d']\n",
    "        c_p_aug = npz_aug['p']\n",
    "        c_s_aug = npz_aug['s']\n",
    "        c_a_aug = npz_aug['a']\n",
    "        \n",
    "        #append\n",
    "        dataset = np.append(dataset,data_aug,axis=0)\n",
    "        cnt_pushup = np.append(cnt_pushup,c_p_aug)\n",
    "        cnt_squat = np.append(cnt_squat,c_s_aug)        \n",
    "        cnt_abs = np.append(cnt_abs,c_a_aug)\n",
    "        \n",
    "    return dataset,cnt_pushup,cnt_squat,cnt_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa406e0d-74a0-4775-89ea-8e77cc683fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset = np.zeros((0,3,35000))\n",
    "label_p = np.zeros(0)\n",
    "label_s = np.zeros(0)\n",
    "label_a = np.zeros(0)\n",
    "\n",
    "train_idx = {}\n",
    "\n",
    "for subject in subject_list1:\n",
    "    use_idx = []\n",
    "    while len(use_idx) < use_num:\n",
    "        r = random.randint(0,19)\n",
    "        if not r in use_idx:\n",
    "            use_idx.append(r)\n",
    "    train_idx[subject] = use_idx\n",
    "    \n",
    "    print('loading dataset :',subject,)\n",
    "    dataset,cnt_p,cnt_s,cnt_a = make_base_dataset(subject,use_idx,aug_num)\n",
    "    \n",
    "    base_dataset = np.append(base_dataset,dataset,axis=0)\n",
    "    label_p = np.append(label_p,cnt_p)\n",
    "    label_s = np.append(label_s,cnt_s)\n",
    "    label_a = np.append(label_a,cnt_a)\n",
    "    \n",
    "for subject in subject_list2:\n",
    "    use_idx = [i for i in range(5)]\n",
    "    print('loading dataset :',subject,)\n",
    "    dataset,cnt_p,cnt_s,cnt_a = make_base_dataset(subject,use_idx,aug_num)\n",
    "    \n",
    "    base_dataset = np.append(base_dataset,dataset,axis=0)\n",
    "    label_p = np.append(label_p,cnt_p)\n",
    "    label_s = np.append(label_s,cnt_s)\n",
    "    label_a = np.append(label_a,cnt_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7724dac1-45f4-4ae5-87e7-50032cdf0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dic = {'p':label_p,'s':label_s,'a':label_a}\n",
    "print(base_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d136947-9f44-4de6-b566-9063c506dce2",
   "metadata": {},
   "source": [
    "### Val Data\n",
    "if target subject is A, B, or C, comment out the code for preparation of the relevant validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f102a24-c9fb-4481-a4e2-690f2bfacc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = np.zeros((0,3,35000))\n",
    "cnt_pushup2 = np.zeros(0)\n",
    "cnt_squat2 = np.zeros(0)\n",
    "cnt_abs2 = np.zeros(0)\n",
    "\n",
    "#Data of the remaining suject A\n",
    "# val_idx = list(range(40))\n",
    "# for i in train_idx['A']:\n",
    "#     val_idx.remove(i)\n",
    "\n",
    "# for i in val_idx:   \n",
    "    \n",
    "#     npz2_n = np.load('../data/raw_data/A/'+str(i)+'.npz')\n",
    "#     acc2_n = npz2_n['d']\n",
    "#     cnt_p2_n = npz2_n['p']\n",
    "#     cnt_s2_n = npz2_n['s']\n",
    "#     cnt_a2_n = npz2_n['a']\n",
    "    \n",
    "#     Data2_n = np.zeros((1,3,35000))\n",
    "#     Data2_n[0,:,:acc2_n.shape[1]] = acc2_n\n",
    "    \n",
    "#     dataset2 = np.append(dataset2,Data2_n,axis=0)\n",
    "#     cnt_pushup2 = np.append(cnt_pushup2,cnt_p2_n)\n",
    "#     cnt_squat2 = np.append(cnt_squat2,cnt_s2_n)\n",
    "#     cnt_abs2 = np.append(cnt_abs2,cnt_a2_n)\n",
    "\n",
    "    \n",
    "#Data of the remaining suject B\n",
    "val_idx = list(range(20))\n",
    "for i in train_idx['B']:\n",
    "    val_idx.remove(i)\n",
    "for i in val_idx:\n",
    "    npz2_t = np.load('../data/raw_data/B/'+str(i)+'.npz')\n",
    "    acc2_t = npz2_t['d']\n",
    "    cnt_p2_t = npz2_t['p']\n",
    "    cnt_s2_t = npz2_t['s']\n",
    "    cnt_a2_t = npz2_t['a']\n",
    "    \n",
    "    Data2_t = np.zeros((1,3,35000))\n",
    "    Data2_t[0,:,:acc2_t.shape[1]] = acc2_t\n",
    "    \n",
    "    dataset2 = np.append(dataset2,Data2_t,axis=0)\n",
    "    cnt_pushup2 = np.append(cnt_pushup2,cnt_p2_t)\n",
    "    cnt_squat2 = np.append(cnt_squat2,cnt_s2_t)\n",
    "    cnt_abs2 = np.append(cnt_abs2,cnt_a2_t)\n",
    "\n",
    "\n",
    "#Data of the remaining suject C\n",
    "val_idx = list(range(20))\n",
    "for i in train_idx['C']:\n",
    "    val_idx.remove(i)\n",
    "for i in val_idx:\n",
    "    npz2_t = np.load('../data/raw_data/C/'+str(i)+'.npz')\n",
    "    acc2_t = npz2_t['d']\n",
    "    cnt_p2_t = npz2_t['p']\n",
    "    cnt_s2_t = npz2_t['s']\n",
    "    cnt_a2_t = npz2_t['a']\n",
    "    \n",
    "    Data2_t = np.zeros((1,3,35000))\n",
    "    Data2_t[0,:,:acc2_t.shape[1]] = acc2_t\n",
    "    \n",
    "    dataset2 = np.append(dataset2,Data2_t,axis=0)\n",
    "    cnt_pushup2 = np.append(cnt_pushup2,cnt_p2_t)\n",
    "    cnt_squat2 = np.append(cnt_squat2,cnt_s2_t)\n",
    "    cnt_abs2 = np.append(cnt_abs2,cnt_a2_t)\n",
    "    \n",
    "    \n",
    "print(dataset2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b43f52a-3103-4715-9434-0928377ab196",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict_val = {'p':cnt_pushup2,'s':cnt_squat2,'a':cnt_abs2}\n",
    "num_data2 = dataset2.shape[0]\n",
    "for i in range(num_data2):\n",
    "    for j in range(3):\n",
    "        dataset2[i][j] = preprocessing.scale(dataset2[i][j])\n",
    "        \n",
    "dataset2 = dataset2.transpose(0,2,1)\n",
    "print(dataset2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b62d1a4-bf8b-4eec-8ac9-5833760be2c5",
   "metadata": {},
   "source": [
    "### make LD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b4a166-32b2-447a-bdc4-a14d65c8aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_DA_dataset(subject,act,use_id,aug_num,aug_num_l,):\n",
    "    dataset = np.zeros((0,3,35000))\n",
    "    cnt = np.zeros(0)\n",
    "    #double and triple\n",
    "    for i in use_id:\n",
    "        for times in ['double','triple']:\n",
    "            path = '../data/'+times+'/'+subject+'/'+str(i)+'.npz'\n",
    "            if os.path.exists(path) == True:\n",
    "                npz = np.load(path)\n",
    "                acc = npz['d']\n",
    "                c = npz[act]\n",
    "\n",
    "                if c <= 20:\n",
    "                    data = np.zeros((1,3,35000))\n",
    "                    data[0,:,:acc.shape[1]] = acc\n",
    "\n",
    "                    dataset = np.append(dataset,data,axis=0)\n",
    "                    cnt = np.append(cnt,c)\n",
    "\n",
    "                    npz_aug = np.load('../data/augmented_data/'+subject+'/'+times+'/'+str(i)+'/'+str(aug_num_l)+'.npz')\n",
    "                    data_aug = npz_aug['d']\n",
    "                    cnt_aug = npz_aug[act]\n",
    "\n",
    "                    dataset = np.append(dataset,data_aug,axis=0)\n",
    "                    cnt = np.append(cnt,cnt_aug)\n",
    "                \n",
    "    #plus\n",
    "    use_id.sort()\n",
    "    use_id2 = use_id.copy()\n",
    "    for i in use_id:\n",
    "        use_id2.remove(i)\n",
    "        for j in use_id2:\n",
    "            plus_id = str(i)+'+'+str(j)\n",
    "            path = '../data/plus2/'+subject+'/'+plus_id+'.npz'\n",
    "            if os.path.exists(path) == True:\n",
    "                npz = np.load(path)\n",
    "                acc = npz['d']\n",
    "                c = npz[act]\n",
    "                \n",
    "                if c <= 20:\n",
    "                    data = np.zeros((1,3,35000))\n",
    "                    data[0,:,:acc.shape[1]] = acc\n",
    "                    \n",
    "                    dataset = np.append(dataset,data,axis=0)\n",
    "                    cnt = np.append(cnt,c)\n",
    "                    \n",
    "                    npz_aug = np.load('../data/augmented_data/'+subject+'/plus2/'+plus_id+'/'+str(aug_num_l)+'.npz')\n",
    "                    data_aug = npz_aug['d']\n",
    "                    cnt_aug = npz_aug[act]\n",
    "                    \n",
    "                    dataset = np.append(dataset,data_aug,axis=0)\n",
    "                    cnt = np.append(cnt,cnt_aug)\n",
    "                    \n",
    "    return dataset,cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda9967b-d871-4cb7-baed-e939958f5340",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0efdc32-6fa4-4c68-b6bf-97071ca8b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_unit = 8\n",
    "kernel_size = 4\n",
    "\n",
    "_input = Input(shape=(35000,3))\n",
    "mask = Masking(mask_value=0.0)(_input)\n",
    "\n",
    "conv_l = Conv1D(hidden_unit,8,padding='same',activation='relu')(mask)\n",
    "conv_l = MaxPooling1D()(conv_l)\n",
    "conv_l = Conv1D(hidden_unit,kernel_size,padding='same',activation='relu')(conv_l)\n",
    "conv_l = MaxPooling1D()(conv_l)\n",
    "conv_l = Conv1D(hidden_unit,2,padding='same',activation='relu')(conv_l)\n",
    "conv_l = MaxPooling1D()(conv_l)\n",
    "conv_l = Dropout(0.5)(conv_l)\n",
    "\n",
    "attention = Conv1D(hidden_unit,8,padding='same',activation='relu')(conv_l)\n",
    "attention = Dropout(0.5)(attention)\n",
    "attention = Conv1D(hidden_unit,8,padding='same',activation='relu')(attention)\n",
    "attention = Activation('sigmoid')(attention)\n",
    "\n",
    "sent_representation = Multiply()([conv_l, attention])\n",
    "sent_representation = Dropout(0.5)(sent_representation)\n",
    "\n",
    "x = Lambda(lambda xin: K.sum(xin,axis=2))(sent_representation)\n",
    "x = Reshape((-1,1))(x)\n",
    "x = Conv1D(hidden_unit,kernel_size,padding='same',activation='relu')(x)\n",
    "x = MaxPooling1D()(x)\n",
    "x = Conv1D(hidden_unit,kernel_size,padding='same',activation='relu')(x)\n",
    "x = MaxPooling1D()(x)\n",
    "x = Conv1D(hidden_unit,kernel_size,padding='same',activation='relu')(x)\n",
    "x = MaxPooling1D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(hidden_unit,activation='relu')(x)\n",
    "_output = Dense(1,activation='linear')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4569a5-e897-4d71-8134-d40ad56f4981",
   "metadata": {},
   "source": [
    "### Roop of training on each three acitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ef8f8-aca6-45dc-96ba-1d67d2942da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "model_dic = {}\n",
    "mae_dic = {}\n",
    "\n",
    "for action in action_list:\n",
    "    print(action)\n",
    "    act = action_dict[action]\n",
    "    \n",
    "    # train data\n",
    "    X = base_dataset\n",
    "    y = label_dic[act]\n",
    "\n",
    "    for subject in subject_list1:\n",
    "        use_idx = train_idx[subject]\n",
    "        print('loading dataset :',subject)\n",
    "        dataset,cnt = make_DA_dataset(subject,act,use_idx,aug_num,aug_num_l)\n",
    "        X = np.append(X,dataset,axis=0)\n",
    "        y = np.append(y,cnt)\n",
    "\n",
    "    for subject in subject_list2:\n",
    "        use_idx = [i for i in range(5)]\n",
    "        print('loading dataset :',subject)\n",
    "        dataset,cnt = make_DA_dataset(subject,act,use_idx,aug_num,aug_num_l)\n",
    "        X = np.append(X,dataset,axis=0)\n",
    "        y = np.append(y,cnt)\n",
    "        \n",
    "    p = np.random.permutation(len(y))\n",
    "    X_train = X[p]\n",
    "    y_train = y[p]\n",
    "    \n",
    "    num_data = X_train.shape[0]\n",
    "    for i in range(num_data):\n",
    "        for j in range(3):\n",
    "            X_train[i][j] = preprocessing.scale(X_train[i][j])\n",
    "\n",
    "    X_train = X_train.transpose(0,2,1)\n",
    "    y_train = y_train/20\n",
    "    \n",
    "    #validation data\n",
    "    X_val = dataset2\n",
    "    y_val = label_dict_val[act]\n",
    "    y_val = y_val/20\n",
    "    \n",
    "    #model compile\n",
    "    model = Model(inputs=_input, outputs=_output)\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    \n",
    "    nb_epoch = 100\n",
    "    plot_losses = keras_utils.PlotLosses()\n",
    "    \n",
    "    #train model \n",
    "    model.fit(X_train,y_train,epochs=nb_epoch,validation_data = (X_val,y_val),callbacks=[plot_losses],verbose=1)\n",
    "    \n",
    "    #validation\n",
    "    predict = model.predict(X_val)\n",
    "    predict = predict[:,0]\n",
    "    mae = mean_absolute_error(np.round(predict*20),y_val*20)\n",
    "    \n",
    "    model_dic[action] = model\n",
    "    mae_dic[action] = mae\n",
    "    \n",
    "    #save model\n",
    "    model.save('../data/pre-trained_model/wo_'+target+'_WeakCounter/'+str(aug_num)+action+'.hdf5')\n",
    "    \n",
    "time2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ef63b-c1a6-4e78-be6f-89bac319ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfeb389-367b-4763-8031-a4a2c948b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mae_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143d4a61-74ae-4dca-812b-fbcf72e7b1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
